# 05｜提示工程（下）：用思维链和思维树提升模型思考质量
你好，我是黄佳，欢迎来到LangChain实战课！

我在 [第4课](https://time.geekbang.org/column/article/700699) 的结尾时说了，你可以尝试用思维链也就是CoT（Chain of Thought）的概念来引导模型的推理，让模型生成更详实、更完备的文案，今天我们就一起看一看CoT的使用。

## 什么是 Chain of Thought

CoT这个概念来源于学术界，是谷歌大脑的Jason Wei等人于2022年在论文《 [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf)（自我一致性提升了语言模型中的思维链推理能力）》中提出来的概念。它提出，如果生成一系列的中间推理步骤，就能够显著提高大型语言模型进行复杂推理的能力。

### Few-Shot CoT

Few-Shot CoT 简单的在提示中提供了一些链式思考示例（Chain-of-Thought Prompting），足够大的语言模型的推理能力就能够被增强。简单说，就是给出一两个示例，然后在示例中写清楚推导的过程。

![](images/701505/f27cec109dff8947d85507b34ce240a0.png)

论文中给出了一个大模型通过思维链做数学题的示例。图左和图右，大模型都读入了OneShot示例，但是图左只给出了答案，而图右则在OneShot示例中给出了解题的具体思路。结果，只给出了答案的模型推理错误，而给出解题思路后，同一个模型生成了正确的答案。

在三种大型语言模型的实验中，CoT在一系列的算术、常识和符号推理任务中都提高了性能。在GSM8K数学问题基准测试中，通过CoT指导后，大模型的表现可以达到当时最先进的准确性。

CoT从概念上非常容易理解，从应用上非常容易操作。虽然简单，但这种思想可以给我们的开发过程带来很多启发。

比如，假设我们正在开发一个AI花店助手，它的任务是帮助用户选择他们想要的花，并生成一个销售列表。在这个过程中，我们可以使用CoT来引导AI的推理过程。

👉 整体指导：你需要跟着下面的步骤一步步的推理。

1. 问题理解：首先，AI需要理解用户的需求。例如，用户可能会说：“今天要参加朋友的生日Party，想送束花祝福她。”我们可以给AI一个提示模板，里面包含示例：“ _**遇到XX问题，我先看自己有**_ _**没有**_ _**相关知识，有的话，就提供答案；没有，就调用工具搜索，有了知识后再试图解决。**_”—— 这就是给了AI一个思维链的示例。

2. 信息搜索：接下来，AI需要搜索相关信息。例如，它可能需要查找哪些花最适合生日派对。

3. 决策制定：基于收集到的信息，AI需要制定一个决策。我们可以通过思维链让他详细思考决策的流程，先做什么后做什么。例如，我们可以给它一个示例：“ _**遇到生日派对送花的情况，我先考虑用户的需求，然后查看鲜花的库存，最后决定推荐一些玫瑰和百合，因为这些花通常适合生日派对。**_”—— 那么有了生日派对这个场景做示例，大模型就能把类似的思维流程运用到其它场景。

4. 生成销售列表：最后，AI使用OutputParser生成一个销售列表，包括推荐的花和价格。

在这个过程中，整体上，思维链引导AI从理解问题，到搜索信息，再到制定决策，最后生成销售列表。这种方法不仅使AI的推理过程更加清晰，也使得生成的销售列表更加符合用户的需求。具体到每一个步骤，也可以通过思维链来设计更为详细的提示模板，来引导模型每一步的思考都遵循清晰准确的逻辑。

其实LangChain的核心组件Agent的本质就是进行好的提示工程，并大量地使用预置的FewShot和CoT模板。这个在之后的课程学习中我们会理解得越来越透彻。

### Zero-Shot CoT

下面的这两个CoT提示模板的例子，来自于Google Research和东京大学的论文《 [大语言模型是零样本推理者](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf)》。

图中的（d）示例非常非常有意思，在Zero-Shot CoT中，你只要简单地告诉模型“ **让我们一步步的思考（Let’s think step by step）**”，模型就能够给出更好的答案！

![](images/701505/09a48be47b3e0e9ec0ae7ebd483d868b.png)

哈哈哈，这样太神奇了吧，这不由得让我联想起最简单的提示工程，角色设定——模型回答之前，先告诉它“你是一个很有经验的XX专家”，模型应该就会在开始胡说八道之前三思。

简单总结一下：Few-Shot CoT，指的就是在带有示例的提示过程中，加入思考的步骤，从而引导模型给出更好的结果。而Zero-Shot CoT，就是直接告诉模型要一步一步地思考，慢慢地推理。

## Chain of Thought 实战

现在，就让我带着你完成一次Chain of Thought的LangChain应用开发实战。

**项目需求**：在这个示例中，你正在开发一个AI运营助手，我们要展示AI如何根据用户的需求推理和生成答案。然后，AI根据当前的用户请求进行推理，提供了具体的花卉建议并解释了为什么选择这些建议。

在这个过程中，AI需要理解客户的需求之后，按部就班的思考，然后给出最符合逻辑的回答。

### CoT的模板设计

针对这个聊天机器人的需求，我设计了下面这样的思维链模板。

> 作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。
>
> 我会按部就班的思考，先理解客户的需求，然后考虑各种鲜花的涵义，最后根据这个需求，给出我的推荐。
>
> 同时，我也会向客户解释我这样推荐的原因。
>
> **示例 1：**
>
> 人类：我想找一种象征爱情的花。
>
> AI：首先，我理解你正在寻找一种可以象征爱情的花。在许多文化中，红玫瑰被视为爱情的象征，这是因为它们的红色通常与热情和浓烈的感情联系在一起。因此，考虑到这一点，我会推荐红玫瑰。红玫瑰不仅能够象征爱情，同时也可以传达出强烈的感情，这是你在寻找的。
>
> **示例 2：**
>
> 人类：我想要一些独特和奇特的花。
>
> AI：从你的需求中，我理解你想要的是独一无二和引人注目的花朵。兰花是一种非常独特并且颜色鲜艳的花，它们在世界上的许多地方都被视为奢侈品和美的象征。因此，我建议你考虑兰花。选择兰花可以满足你对独特和奇特的要求，而且，兰花的美丽和它们所代表的力量和奢侈也可能会吸引你。

AI的模板开始于对其角色的阐述，并给出了一些先前的对话示例（Few-Shot Learning）来帮助AI理解如何处理这种类型的请求。这些示例展示了AI如何根据思维链进行思考，给出深思熟虑之后的答案。

### 程序的完整框架

程序的完整代码如下：

```plain
# 设置环境变量和API密钥
import os
os.environ["OPENAI_API_KEY"] = '你的OpenAI API Key'

# 创建聊天模型
from langchain.chat_models import ChatOpenAI
llm = ChatOpenAI(temperature=0)

# 设定 AI 的角色和目标
role_template = "你是一个为花店电商公司工作的AI助手, 你的目标是帮助客户根据他们的喜好做出明智的决定"

# CoT 的关键部分，AI 解释推理过程，并加入一些先前的对话示例（Few-Shot Learning）
cot_template = """
作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。

我会按部就班的思考，先理解客户的需求，然后考虑各种鲜花的涵义，最后根据这个需求，给出我的推荐。
同时，我也会向客户解释我这样推荐的原因。

示例 1:
  人类：我想找一种象征爱情的花。
  AI：首先，我理解你正在寻找一种可以象征爱情的花。在许多文化中，红玫瑰被视为爱情的象征，这是因为它们的红色通常与热情和浓烈的感情联系在一起。因此，考虑到这一点，我会推荐红玫瑰。红玫瑰不仅能够象征爱情，同时也可以传达出强烈的感情，这是你在寻找的。

示例 2:
  人类：我想要一些独特和奇特的花。
  AI：从你的需求中，我理解你想要的是独一无二和引人注目的花朵。兰花是一种非常独特并且颜色鲜艳的花，它们在世界上的许多地方都被视为奢侈品和美的象征。因此，我建议你考虑兰花。选择兰花可以满足你对独特和奇特的要求，而且，兰花的美丽和它们所代表的力量和奢侈也可能会吸引你。
"""
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate
system_prompt_role = SystemMessagePromptTemplate.from_template(role_template)
system_prompt_cot = SystemMessagePromptTemplate.from_template(cot_template)

# 用户的询问
human_template = "{human_input}"
human_prompt = HumanMessagePromptTemplate.from_template(human_template)

# 将以上所有信息结合为一个聊天提示
chat_prompt = ChatPromptTemplate.from_messages([system_prompt_role, system_prompt_cot, human_prompt])

prompt = chat_prompt.format_prompt(human_input="我想为我的女朋友购买一些花。她喜欢粉色和紫色。你有什么建议吗?").to_messages()

# 接收用户的询问，返回回答结果
response = llm(prompt)
print(response)

```

程序中，首先设置环境变量OpenAI的API密钥，以便能够使用OpenAI的GPT-4模型。然后创建聊天模型：通过调用 ChatOpenAI 类，创建了一个聊天模型。设置 temperature=0 可以让模型生成更确定性的回答，即输出更倾向于最可能的结果。

接着定义了AI的角色和目标，该AI为花店电商公司的助手，其目标是根据客户的喜好来提供购买建议。紧接着，定义 CoT 模板，其中包括了AI的角色和目标描述、思考链条以及遵循思考链条的一些示例，显示了AI如何理解问题，并给出建议。

之后，我使用了PromptTemplate的from\_template方法，来生成相应的询问模板。其中包括用于指导模型的SystemMessagePromptTemplate和用于传递人类问题的HumanMessagePromptTemplate。

然后，我使用了ChatPromptTemplate.from\_messages方法，整合上述定义的角色，CoT模板和用户询问，生成聊天提示。

最后，将生成的聊天提示输入模型中，获得模型的回答，并打印出来。

在Few-Shot CoT提示的指引之下，模型针对我们的问题，从问题中的具体需求出发，返回了不错的建议。

_**现在，根据你的需求：你正在寻找你的女朋友喜欢的粉色和紫色的花。**_

_**首先，我从理解你的需求出发，只会推荐粉色或紫色，或者两者的组合的花。这些可能包括粉色的玫瑰，紫色的兰花，或者是粉色和紫色的花的混合花束。玫瑰是象征爱情和亲情的经典符号，而兰花象征着美丽和力量。这两种花都蕴含很棒的内涵。当然了，无论你选择哪种花卉，重要的是表达出你对她的爱和关心。记得附上一张温馨的贺卡，写下你的真挚祝福。**_

## Tree of Thought

CoT这种思想，为大模型带来了更好的答案，然而，对于需要探索或预判战略的复杂任务来说，传统或简单的提示技巧是不够的。基于CoT的思想，Yao和Long等人几乎在同一时间在论文《 [思维之树：使用大型语言模型进行深思熟虑的问题解决](https://arxiv.org/pdf/2305.10601.pdf)》和《 [大型语言模型指导的思维之树](https://arxiv.org/pdf/2305.08291.pdf)》中，进一步提出了思维树（Tree of Thoughts，ToT）框架，该框架基于思维链提示进行了总结，引导语言模型探索把思维作为中间步骤来解决通用问题。

ToT是一种解决复杂问题的框架，它在需要多步骤推理的任务中，引导语言模型搜索一棵由连贯的语言序列（解决问题的中间步骤）组成的思维树，而不是简单地生成一个答案。ToT框架的核心思想是：让模型生成和评估其思维的能力，并将其与搜索算法（如广度优先搜索和深度优先搜索）结合起来，进行系统性地探索和验证。

![](images/701505/6eec83ffe1a5f37d245520535d65f8a0.png)

ToT 框架为每个任务定义具体的思维步骤和每个步骤的候选项数量。例如，要解决一个数学推理任务，先把它分解为3个思维步骤，并为每个步骤提出多个方案，并保留最优的5个候选方案。然后在多条思维路径中搜寻最优的解决方案。

这种方法的优势在于，模型可以通过观察和评估其自身的思维过程，更好地解决问题，而不仅仅是基于输入生成输出。这对于需要深度推理的复杂任务非常有用。此外，通过引入强化学习、集束搜索等技术，可以进一步提高搜索策略的性能，并让模型在解决新问题或面临未知情况时有更好的表现。

下面我们应用ToT的思想，给出一个鲜花运营方面的示例。

> 假设一个顾客在鲜花网站上询问：“我想为我的妻子购买一束鲜花，但我不确定应该选择哪种鲜花。她喜欢淡雅的颜色和花香。”
>
> AI（使用ToT框架）：
>
> **思维步骤1**：理解顾客的需求。
>
> 顾客想为妻子购买鲜花。
>
> 顾客的妻子喜欢淡雅的颜色和花香。
>
> **思维步骤2**：考虑可能的鲜花选择。
>
> 候选1：百合，因为它有淡雅的颜色和花香。
>
> 候选2：玫瑰，选择淡粉色或白色，它们通常有花香。
>
> 候选3：紫罗兰，它有淡雅的颜色和花香。
>
> 候选4：桔梗，它的颜色淡雅但不一定有花香。
>
> 候选5：康乃馨，选择淡色系列，它们有淡雅的花香。
>
> **思维步骤3**：根据顾客的需求筛选最佳选择。
>
> 百合和紫罗兰都符合顾客的需求，因为它们都有淡雅的颜色和花香。
>
> 淡粉色或白色的玫瑰也是一个不错的选择。
>
> 桔梗可能不是最佳选择，因为它可能没有花香。
>
> 康乃馨是一个可考虑的选择。
>
> **思维步骤4**：给出建议。
>
> “考虑到您妻子喜欢淡雅的颜色和花香，我建议您可以选择百合或紫罗兰。淡粉色或白色的玫瑰也是一个很好的选择。希望这些建议能帮助您做出决策！”

这个例子，可以作为FewShot示例之一，传递给模型，让他学着实现ToT。

通过在具体的步骤中产生多条思考路径，ToT 框架为解决复杂问题提供了一种新的方法，这种方法结合了语言模型的生成能力、搜索算法以及强化学习，以达到更好的效果。

## 总结时刻

这节课我们介绍了Chain of Thought（CoT，即“思维链”）和Tree of Thoughts（ToT，即“思维树”）这两个非常有趣的概念，并探讨了如何利用它们引导大型语言模型进行更深入的推理。

- CoT的核心思想是通过生成一系列中间推理步骤来增强模型的推理能力。在Few-Shot CoT和Zero-Shot CoT两种应用方法中，前者通过提供链式思考示例传递给模型，后者则直接告诉模型进行要按部就班的推理。
- ToT进一步扩展了CoT的思想，通过搜索由连贯的语言序列组成的思维树来解决复杂问题。我通过一个鲜花选择的实例，展示了如何在实际应用中使用ToT框架。


  有朋友在GitHub上开了一个 [Repo](https://github.com/kyegomez/tree-of-thoughts)，专门给大家介绍ToT的应用方法和实例，他们还给出了几个非常简单的通用ToT提示语，就像下面这样。

> 请你模拟三位出色、逻辑性强的专家合作回答一个问题。每个人都详细地解释他们的思考过程，考虑到其他人之前的解释，并公开承认错误。在每一步，只要可能，每位专家都会在其他人的思考基础上进行完善和建设，并承认他们的贡献。他们继续，直到对问题有一个明确的答案。为了清晰起见，您的整个回应应该是一个Markdown表格。
>
> 问题是…

![图片](images/701505/d719e10a2b045f5a70993b6135ef503c.png)

如果你有兴趣，可以去这个Repo里面看一看。

## 思考题

1. 我们的CoT实战示例中使用的是Few-Shot CoT提示，请你把它换为Zero-Shot CoT，跑一下程序，看看结果。
2. 请你设计一个你工作场景中的任务需求，然后用ToT让大语言模型帮你解决问题。

期待在留言区看到你的分享，我们一起交流探讨，共创一个好的学习氛围。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。

## 延伸阅读

1. 论文，自我一致性提升了语言模型中的思维链推理能力， [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2205.11916.pdf)，Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., & Zhou, D. (2023). Self-Consistency Improves Chain of Thought Reasoning in Language Models. Proceedings of the International Conference on Learning Representations (ICLR). arXiv preprint arXiv:2203.11171.
2. 论文，大语言模型是零样本推理者， [Large Language Models are Zero-Shot Reasoners](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf)，Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2023). Large Language Models are Zero-Shot Reasoners. arXiv preprint arXiv:2205.11916v4.
3. 论文，思维之树：使用大型语言模型进行深思熟虑的问题解决， [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)，Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y., & Narasimhan, K. (2023). Tree of Thoughts: Deliberate Problem Solving with Large Language Models. arXiv preprint arXiv:2305.10601.
4. 论文，大型语言模型指导的思维之树， [Large Language Model Guided Tree-of-Thought](https://arxiv.org/abs/2305.08291)，Long, J. (2023). Large Language Model Guided Tree-of-Thought. arXiv preprint arXiv:2305.08291.
5. GitHub链接， [tree-of-thoughts](https://github.com/kyegomez/tree-of-thoughts)，把ToT算法导入你的大模型应用，目前3.3K颗星